{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from get_data import get_yield\n",
    "from statsmodels.tsa.api import VAR\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "\n",
    "# Yield data\n",
    "df = get_yield(term=10)\n",
    "# to weekly and take diff\n",
    "df = df.resample(\"W-FRI\").last()\n",
    "df = df.diff().dropna()\n",
    "# Skip last two years of data\n",
    "df = df.truncate(after = pd.to_datetime('2023-2-10'))\n",
    "\n",
    "# corr = df_1.corr()\n",
    "\n",
    "Y = df.copy()\n",
    "Y = Y.sort_index()\n",
    "Y = Y.apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Granger causlity test (just for UK-CAN for now)\n",
    "# Might need to make dict of dicts for all of the combinations\n",
    "gc_test_result = grangercausalitytests(Y[['CAN', 'UK']], maxlag=5, addconst=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAR\n",
    "model = VAR(Y)\n",
    "order = model.select_order(maxlags=7)\n",
    "print(order.summary())\n",
    "p = order.selected_orders[\"aic\"]\n",
    "results = model.fit(p)\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Granger Causality of everything\n",
    "\n",
    "# Statistical meaning, things with a low enough p value improve the prediction of of Y inside the VAR, eg: lags of CAN help\n",
    "# predict the UK change in yield\n",
    "\n",
    "for caused in results.names:\n",
    "    for causing in results.names:\n",
    "        if caused != causing:\n",
    "            test = results.test_causality(caused, [causing], kind='f')\n",
    "            print(f\"{causing} -> {caused}: p-value = {test.pvalue}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fevd = results.fevd(10)\n",
    "fevd.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generalized_fevd(var_results, H=10, normalize=True):\n",
    "    \"\"\"\n",
    "    Generalized FEVD (Pesaran-Shin) for a fitted statsmodels VARResults.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    var_results : statsmodels.tsa.vector_ar.var_model.VARResults\n",
    "        Fitted VAR results (e.g., `results = model.fit(p)`).\n",
    "    H : int\n",
    "        Forecast horizon in steps (e.g., weeks). Uses horizons 0..H-1 in sums.\n",
    "    normalize : bool\n",
    "        If True, row-normalize so contributions sum to 1 for each equation at each horizon.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    fevd : np.ndarray\n",
    "        Array of shape (H, n, n) where fevd[h, i, j] is contribution of shock j\n",
    "        to variable i at horizon h (h=0..H-1). If normalize=True, each row sums to 1.\n",
    "    names : list\n",
    "        Variable names in order.\n",
    "    \"\"\"\n",
    "    names = list(var_results.names)\n",
    "    n = len(names)\n",
    "\n",
    "    # Moving-average (MA) representation coefficients Psi_k\n",
    "    # Psi has shape (H, n, n) with Psi[0] = I\n",
    "    Psi = var_results.ma_rep(H)\n",
    "\n",
    "    # Residual covariance matrix Σ (n x n)\n",
    "    Sigma = np.asarray(var_results.sigma_u)\n",
    "\n",
    "    # Precompute denominators: denom[h, i] = sum_{k=0}^{h} e_i' Psi_k Σ Psi_k' e_i\n",
    "    # We'll build horizon-by-horizon contributions using cumulative sums.\n",
    "    fevd = np.zeros((H, n, n), dtype=float)\n",
    "\n",
    "    # For each horizon h, compute cumulative sums from k=0..h\n",
    "    for h in range(H):\n",
    "        denom = np.zeros(n, dtype=float)\n",
    "        numer = np.zeros((n, n), dtype=float)\n",
    "\n",
    "        for k in range(h + 1):\n",
    "            A = Psi[k] @ Sigma  # (n x n)\n",
    "            # denom_i adds (Psi_k Σ Psi_k')_ii\n",
    "            denom += np.diag(A @ Psi[k].T)\n",
    "\n",
    "            # numer_{i,j} adds (e_i' Psi_k Σ e_j)^2 / σ_jj\n",
    "            # e_i' Psi_k Σ e_j is just A[i, j]\n",
    "            numer += (A ** 2)\n",
    "\n",
    "        # divide each column j by σ_jj (generalized shock scaling)\n",
    "        sigma_diag = np.diag(Sigma).copy()\n",
    "        # avoid division by 0 if any diag is 0 (shouldn't happen in sane VAR)\n",
    "        sigma_diag[sigma_diag == 0] = np.nan\n",
    "\n",
    "        numer = numer / sigma_diag  # broadcasts across rows\n",
    "\n",
    "        # contribution at horizon h\n",
    "        # θ_ij(h) = numer_ij / denom_i\n",
    "        # (broadcast denom_i across columns)\n",
    "        fevd[h] = numer / denom[:, None]\n",
    "\n",
    "        if normalize:\n",
    "            row_sums = fevd[h].sum(axis=1, keepdims=True)\n",
    "            fevd[h] = fevd[h] / row_sums\n",
    "\n",
    "    return fevd, names\n",
    "\n",
    "\n",
    "def fevd_table(fevd, names, var, horizons=None):\n",
    "    \"\"\"\n",
    "    Convenience: return a DataFrame for one dependent variable across horizons.\n",
    "    var : str, dependent variable name.\n",
    "    horizons : iterable of int or None -> use all.\n",
    "    \"\"\"\n",
    "    idx = names.index(var)\n",
    "    H = fevd.shape[0]\n",
    "    if horizons is None:\n",
    "        horizons = range(H)\n",
    "\n",
    "    rows = []\n",
    "    for h in horizons:\n",
    "        rows.append(fevd[h, idx, :])\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=names, index=list(horizons))\n",
    "    df.index.name = \"horizon\"\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates a table which shows how much of the yields is caused locally, versus impacted from others (I think)\n",
    "gfevd, names = generalized_fevd(results, H=10, normalize=True)\n",
    "uk_g = fevd_table(gfevd, names, \"UK\")\n",
    "can_g = fevd_table(gfevd, names, \"CAN\")\n",
    "us_g = fevd_table(gfevd, names, \"US\")\n",
    "\n",
    "uk_g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates the Diebold-Yilmaz spillover table which is found in their papers\n",
    "\n",
    "theta = gfevd[9]\n",
    "N = theta.shape[0]\n",
    "\n",
    "total_spillover = (theta.sum() - np.trace(theta)) / N * 100\n",
    "\n",
    "to_others = theta.sum(axis=0) - np.diag(theta)\n",
    "from_others = theta.sum(axis=1) - np.diag(theta)\n",
    "net = to_others - from_others\n",
    "\n",
    "spill = pd.DataFrame({\n",
    "    \"TO_others\": to_others,\n",
    "    \"FROM_others\": from_others,\n",
    "    \"NET\": net\n",
    "}, index=names).sort_values(\"NET\", ascending=False)\n",
    "\n",
    "total_spillover, spill"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
